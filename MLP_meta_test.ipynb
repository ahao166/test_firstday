{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio \n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from copy import deepcopy,copy\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 1444)\n"
     ]
    }
   ],
   "source": [
    "data = sio.loadmat('D:/deeplearn/metaDataMine_MLP.mat')\n",
    "# data = np.array(data['data'])#是L不是1\n",
    "# data = data.reshape(92,40,1444)\n",
    "# print(data.shape)\n",
    "# label = sio.loadmat('D:/deeplearn/label_leibiao_meta.mat')\n",
    "# label = np.array(label['label'])\n",
    "# label = np.linspace(0,3679,3680)\n",
    "# print(label)\n",
    "e = torch.randperm(460)\n",
    "\n",
    "train_data = np.array(data['train_data'])#,[40:60]]#[0:20;40:60]\n",
    "train_label = np.array(data['train_label'])\n",
    "train_data = train_data\n",
    "train_label = train_label\n",
    "print(train_data.shape)\n",
    "\n",
    "# print(train_label)\n",
    "\n",
    "train_data = torch.Tensor(train_data)\n",
    "train_label = torch.LongTensor(train_label)\n",
    "train_label = train_label.squeeze()\n",
    "test_data = torch.Tensor(data['test_data'])\n",
    "test_label = torch.LongTensor(data['test_label'])\n",
    "test_label = test_label.squeeze()\n",
    "# c = np.append(w[0:100,:],q[100:1000,:],axis=0)#[c[:,0:250],f[:,0:250]]\n",
    "# c = np.array(c)\n",
    "# print(test_data.size)\n",
    "# print(test_label)\n",
    "# f = torch.Tensor(f[e])\n",
    "# c = c.t()\n",
    "# c = np.array(c)\n",
    "# d = label['label']\n",
    "# g = torch.LongTensor(d)\n",
    "# g = g.squeeze()\n",
    "# # d = np.array(label['label'])\n",
    "# d = torch.LongTensor(d[e])\n",
    "# d = d.squeeze() \n",
    "# # datasets = {\"train\": c, \"train_label\": d}\n",
    "# print(d)\n",
    "# data\n",
    "# print(np.array(data['E']).shape)\n",
    "# print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, out):\n",
    "        super(Net,self).__init__()\n",
    "       \n",
    "        self.fc1 = nn.Linear(in_dim,800)\n",
    "        self.fc2 = nn.Linear(800,400)\n",
    "        self.fc3 = nn.Linear(400,200)\n",
    "#         self.fc3 = nn.Linear(800,200)\n",
    "#         self.fc2 = nn.Linear(300,100)\n",
    "        self.fc4 = nn.Linear(200,out)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         running_mean = nn.Parameter(torch.zeros(800), requires_grad= False)\n",
    "#         running_var = nn.Parameter(torch.zeros(800), requires_grad= False)\n",
    "#         x = F.batch_norm(x,running_mean=running_mean,running_var=running_var)\n",
    "#         x = F.dropout(x,0.3)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x,0.3)\n",
    "#         x = F.batch_norm(x,0.1,0.1)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim, out, p = 1444,92,0\n",
    "model = Net(in_dim,out)\n",
    "cp = []\n",
    "ap = []\n",
    "ao = []\n",
    "co = []\n",
    "loss = nn.CrossEntropyLoss()\n",
    "lr, weight_decay,momentum = 0.001,0.0001,0.9\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = lr,weight_decay=weight_decay)\n",
    "# @torchsnooper.snoop()\n",
    "for t in range(2000): \n",
    "    p = 0\n",
    "    cp = []\n",
    "    for i in range(56):\n",
    "        p=p+1\n",
    "        model.train()\n",
    "        y_pred= model(train_data[(15*(p-1)):(15*p)].float())\n",
    "#         print(y_pred.shape)\n",
    "        lossp = loss(y_pred, train_label[(15*(p-1)):(15*p)].long())\n",
    "        optimizer.zero_grad()\n",
    "        lossp.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = torch.max(y_pred, 1)#1是每行的最大值\n",
    "#         print(pred)\n",
    "#         print(train_label[(40*(p-1)):(40*p)].long())\n",
    "        num_correct = (pred == train_label[(15*(p-1)):(15*p)].long()).sum()\n",
    "        accuracy = (pred == train_label[(15*(p-1)):(15*p)].long()).float().mean()\n",
    "        with torch.no_grad():\n",
    "            accuracy = np.array(accuracy)\n",
    "            cp.append(accuracy)\n",
    "            ao.append(np.array(lossp))\n",
    "    a = np.array(cp).mean()\n",
    "    b = np.array(ao).mean()\n",
    "    \n",
    "    ap.append(accuracy)\n",
    "    co.append(b)\n",
    "#     print(a.shape)\n",
    "#     if t % 2 == 0:\n",
    "        \n",
    "#         model.eval()\n",
    "#         y_pred = model(test_data)\n",
    "#         _, pred = torch.max(y_pred, 1)\n",
    "# #         print(\"pred:\",pred)\n",
    "# #         print(\"testlabel\",test_label)\n",
    "# #         print(pred,d)\n",
    "#         acc = (pred == test_label.long()).float().mean()\n",
    "#         print(\"trainAcc:%.6f, %.6f, loss:%.6f}\"%(accuracy,acc,lossp))\n",
    "#         print(accuracy)\n",
    "sio.savemat('mlpmeta.mat',{'ap':ap,'co':co})\n",
    "# torch.save(model,'D:/d2l-zh/model.pth') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sio.savemat('metaSAE.mat',{'PP':cp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
